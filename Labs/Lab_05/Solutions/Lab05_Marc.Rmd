---
title: "Computational Statistics (732A90) Lab05"
author: "Christoforos Spyretos, Marc Braun, Marketos Damigos, Patrick Siegfried Hiemsch & Prakhar"
date: "`r Sys.Date()`"
output: pdf_document
papersize : a4
---

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```


## Question 1

In the first step, 2000 randomly bootstrapped datasets are sampled from the original data.
After that, a prediction model is trained using the `loess` function and the test statistic
calculated for each of the bootstrapped datasets, resulting in the following distribution of the
statistic.

```{r, echo=FALSE}
data <- read.csv("lottery.csv", sep = ";")
Y <- data$Draft_No
X <- data$Day_of_year

set.seed(12345)
bootstrap <- matrix(nrow=2000, ncol=length(X))
bootstrap_Y <- matrix(nrow=2000, ncol=length(X))
for (i in 1:2000) {
  bootstrap[i,] <- sample(X, replace = TRUE)
  bootstrap_Y[i,] <- Y[bootstrap[i,]]
}

T <- c()
for (i in 1:nrow(bootstrap)) {
  temp_data <- data.frame("Draft_No" = bootstrap_Y[i, ], "Day_of_year" = bootstrap[i,])
  model <- loess(Draft_No ~ Day_of_year, data=temp_data)
  Xb <- bootstrap[i,max(which(predict(model, bootstrap[i,]) == max(predict(model, bootstrap[i,]))))]
  Xa <- bootstrap[i,min(which(predict(model, bootstrap[i,]) == min(predict(model, bootstrap[i,]))))]
  T <- append(T, (predict(model, Xb) - predict(model,  Xa)) / (Xb - Xa))
}

hist(T, breaks = 30)

```
From the distribution one can conclude that the value of the statistic seems to be skewed to the left of zero, leading to the conclusion that the "lottery" is not truly random.

## Question 2

```{r}
data <- read.csv("prices1.csv", sep = ";")


# Task 1
library(ggplot2)
ggplot(data) +
  geom_histogram(aes(Price)) +
  geom_vline(xintercept = mean(data$Price), color="red")
print(paste("The mean of the prices is", round(mean(data$Price), 2)))


#Task 2 and 3
library(boot)
test_stat <- function(data, indices){
  return(mean(data[indices]))
}
boot_obj <- boot(data$Price, test_stat, 1000)
cis <- boot.ci(boot.out = bootstrap,type = c("perc", "bca", "norm"))
plot(boot_obj)
print(boot_obj)
print(cis)
print(paste("The bias corrected estimate is", round(2* boot_obj$t0 - mean(boot_obj$t), 3)))
print(paste("The variance is", round(sd(boot_obj$t)^2, 3)))


# Task 4

r <- 55 # number of groups
n <- nrow(data)
k <- n / r # groupsize
jackknife <- matrix(nrow=r, ncol=k)
indices <- 1:n
samples <- matrix(nrow=r, ncol=n-k)
for (i in 1:r) {
  jackknife[i,] <- sample(indices, k)
  indices <- indices[-which(indices %in% jackknife[i,])]
  samples[i,] <- data$Price[-jackknife[i,]]
}

jacknife_var <- function(samples, D){
  r <- nrow(samples)
  T_star <- rep(NA, r)
  for (i in 1:r) {
      T_star[i] <- r * mean(D) - (r-1) * mean(samples[i,])
  }
  JT <- mean(T_star)
  return(1 / (r * (r-1)) * sum((T_star - JT)^2))
}
jacknife_var(samples, data$Price)
```


The mean of 1080.47 is located in all of the 95-Percentiles.





























