---
title: "Computational Statistics (732A90) Lab04"
author: "Christophoros Spyretos, Marc Braun, Marketos Damigos, Patrick Siegfried Hiemsch & Prakhar"
date: "`r Sys.Date()`"
output: pdf_document
papersize : a4
---

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
```

# Question 1



# Question 2

## Task 1

The formula of the Bayes Theorem is given by $P(\mu|Y) = \frac{P(Y|\mu)P(\mu)}{\int{P(Y|\mu)}P(\mu)d\mu} = \frac{P(Y|\mu)P(\mu)}{P(Y)}$. The $P(Y)$ is the model evidence, which it does not depend on $\mu$, thus we have the following relation,  $P(\mu|Y) \varpropto P(Y|\mu)P(\mu)$. In the following steps we are going to calculate the likelihood $P(Y|\mu)$ and the prior $P(\mu)$.

The likelihood formula of the Normal distribution is given by:
$$
\begin{aligned}
L(\mu_{i},\sigma^2;y_{1},y_{2},.....,y_{n}) &= \prod_{i=1}^{n}f_{Y}(y_{j};\mu_{i},\sigma^2) \\
&= \prod_{i=1}^{n}\frac{1}{\sqrt{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_{i}-\mu_{i})^2} \\
&= \frac{1}{\sqrt[n]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_{i}-\mu_{i})^2} \Leftrightarrow \\
P(Y|\mu) &= \frac{1}{\sqrt[n]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_{i}-\mu_{i})^2}
\end{aligned}
$$
The general prior formula is given by $p(\mu)=p(\mu_{1})p(\mu_{i+1}|\mu_{i}).....p(\mu_{n}|\mu_{n-1})$. 

In our case, the prior formula is given by: 
$$
\begin{aligned}
p(\mu) &=p(\mu_{1})p(\mu_{2}|\mu_{1})p(\mu_{2})p(\mu_{3}|\mu_{2}).....p(\mu_{n}|\mu_{n-1}) \\
&=1p(\mu_{2}|\mu_{1})p(\mu_{2})p(\mu_{3}|\mu_{2}).....p(\mu_{n}|\mu_{n-1}) \\ &=p(\mu_{2}|\mu_{1})p(\mu_{2})p(\mu_{3}|\mu_{2}).....p(\mu_{n}|\mu_{n-1}) \\
&=\prod_{i=2}^{n}p(\mu_{i}|\mu_{i-1}) \\
&=\frac{1}{\sqrt[n-1]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=2}^{n}(\mu_{i}-\mu_{i-1})^2}
\end{aligned}
$$

## Task 2 

Bayesâ€™ Theorem is used to get the posterior up to a constant proportionality.

$$
\begin{aligned}
P(\mu|Y)\varpropto P(Y|\mu)P(\mu)
&= \frac{1}{\sqrt[n]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_{i}-\mu_{i})^2}\frac{1}{\sqrt[n-1]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}\sum_{i=2}^{n}(\mu_{i}-\mu_{i-1})^2} \\
&= \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{-\frac{1}{2\sigma^2}(\sum_{i=1}^{n}(y_{i}-\mu_{i})^2 + \sum_{i=2}^{n}(\mu_{i}-\mu_{i-1})^2)}
\end{aligned}
$$

To separate the above formula the Hint A, Hint B and Hint C were used.

$$
\begin{aligned}
p(\mu_1|\vec\mu_{-1},\vec Y)
&=\frac{p(\vec \mu,\vec Y)}{p(\vec \mu_{-1},\vec Y)}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}} exp^{(-\frac{(y_1-\mu_1)^2+(\mu_2-\mu_1)^2}{2\sigma^2})}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{(-\frac{(\mu_1-(y_1+\mu_{2})/{2})^2}{\frac{2\sigma^2}{2}})}
\end{aligned}
$$

$$
\begin{aligned}
p(\mu_i|\vec\mu_{-i},\vec{Y})&=\frac{p(\vec \mu,\vec Y)}{p(\vec \mu_{-i},\vec Y)}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{(-\frac{(y_i-\mu_i)^2+(\mu_{i+1}-\mu_{i})^2+(\mu_{i}-\mu_{i-1})^2}{2\sigma^2})}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{(-\frac{(\mu_i-(y_i+\mu_{i-1}+\mu_{i+1})/{3})^2}{\frac{2\sigma^2}{3}})}
\end{aligned}
$$

$$
\begin{aligned}
p(\mu_n|\vec\mu_{-n},\vec Y)
&= \frac{p(\vec \mu,\vec Y)}{p(\vec \mu_{-n},\vec Y)}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{(-\frac{(y_n-\mu_n)^2+(\mu_{n}-\mu_{n-1})^2}{2\sigma^2})}\\
&\varpropto \frac{1}{\sqrt[\frac{2n-1}{n(n-1)}]{2\pi\sigma^2}}exp^{(-\frac{(\mu_n-(y_n+\mu_{n-1})/{2})^2}{\frac{2\sigma^2}{2}})}\\
\end{aligned}
$$

$$ 
(\mu_i|\vec\mu_{-i},\vec{Y})\sim
\left\{
  \begin{array}{llr}
    N(\frac{y_1+\mu_2}{2},\frac{\sigma^2}{2})       & i=1\\
    N(\frac{y_i+\mu_{i-1}+\mu_{i+1}}{3},\frac{\sigma^2}{3}) & Otherwise\\
    N(\frac{y_n+\mu_{n-1}}{2},\frac{\sigma^2}{2})       & i=n
  \end{array} 
\right. 
$$

## Task 3

```{r}
load("./chemical.RData")
n = 1000
dim = length(Y)
mu_init = rep(0, dim)
sigma = 0.2

gibbs_sampler = function(n, dim, data, mu_init,sigma){
  
  res = matrix(0, nrow=n+1, ncol=dim)
  res[1,] = mu_init
  
    for (i in 2:nrow(res)) {
      res[i,1] = rnorm(1,(data[1]+res[i-1,2])/2,sqrt(sigma^2/2))
      for (j in 2:(dim-1)) {
        res[i,j] = rnorm(1,(data[j]+res[i,j-1]+res[i-1,j+1])/3,sqrt(sigma^2/3))
      }
      res[i,dim] = rnorm(1,(data[dim]+res[i,dim-1])/2,sqrt(sigma^2/2))
    }
  
  return(res)
}

res = gibbs_sampler(n, dim, Y, mu_init,sigma)

library(ggplot2)

mean_res = colMeans(res)

data = data.frame("X"=X,"Y"=Y, "Gibbs"=mean_res)

ggplot(data)+
  geom_line(aes(x=X, y=Y), color = "#d1495b") +
  geom_line(aes(x=X, y=Gibbs), color = "#00A5FF")
```

## Task 4

```{r}
data2 = data.frame("n" =1:1001, "mean_res" = rowMeans(res))

ggplot(data2, aes(x=n, y=mean_res))+
  geom_line(color = "#00A5FF")
```

